version: "3.9"

services:
  qwen:
      image: vllm/vllm-openai:latest
      command: >
        --model /models/Qwen2.5-7B-Instruct
        --host 0.0.0.0
        --port 8000
        --dtype auto              
        --gpu-memory-utilization 0.9   # 显存利用率
        --tensor-parallel-size 2       # 2卡机器
      volumes:
        - /home/models:/models
      deploy:
        resources:
          reservations:
            devices:
              - capabilities: [gpu]
      ports:
        - "127.0.0.1:8000:8000"
      ipc: host                     # 强烈建议加这个（vLLM 推荐，共享内存）

  chattts:
    build:
      context: .
      dockerfile: dockerfiles/Dockerfile.chattts
    volumes:
      - /home/models:/models
      - /home/ai-services:/services
    deploy:
      resources:
        reservations:
          devices:
            - capabilities: [gpu]
    ports:
      - "127.0.0.1:8001:8001"

  whisper:
    build:
      context: .
      dockerfile: dockerfiles/Dockerfile.whisper
    volumes:
      - /home/models:/models
      - /home/ai-services:/services
    deploy:
      resources:
        reservations:
          devices:
            - capabilities: [gpu]
    ports:
      - "127.0.0.1:8002:8002"

  nginx:
    image: nginx:1.25
    volumes:
      - ./nginx/nginx.conf:/etc/nginx/nginx.conf
    ports:
      - "9007:9007"
    depends_on:
      - qwen
      - chattts
      - whisper
